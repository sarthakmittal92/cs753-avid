{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deY1RziORObc",
        "outputId": "e087338d-53c9-467c-8f77-07f3668346c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# https://drive.google.com/drive/folders/1Tj1rGwyztX2MRlV1DkeBAPTbtoC9_-84?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# clone the repo\n",
        "%cd /content/drive/MyDrive\n",
        "%mkdir -p cs753-hacker\n",
        "%cd cs753-hacker\n",
        "!git clone https://github.com/facebookresearch/AVID-CMA\n",
        "\n",
        "# get the checkpoint\n",
        "%cd AVID-CMA\n",
        "%mkdir -p checkpoints/AVID/Kinetics/Cross-N1024\n",
        "!wget https://dl.fbaipublicfiles.com/avid-cma/checkpoints/AVID_Kinetics_Cross-N1024_checkpoint.pth.tar\n",
        "!mv AVID_Kinetics_Cross-N1024_checkpoint.pth.tar checkpoint.pth.tar\n",
        "!mv checkpoint.pth.tar checkpoints/AVID/Kinetics/Cross-N1024\n",
        "%cd ..\n",
        "\n",
        "# get the dataset\n",
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "!sudo apt install unrar\n",
        "!unrar x hmdb51_org.rar\n",
        "%mkdir -p Dataset\n",
        "!rm -rf hmdb51_org.rar\n",
        "%mv *.rar Dataset\n",
        "\n",
        "# get the splits\n",
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
        "!unrar x test_train_splits.rar\n",
        "%mkdir -p Data\n",
        "!mv Dataset Data\n",
        "!mv testTrainMulti_7030_splits Splits\n",
        "!mv Splits Data\n",
        "\n",
        "import os\n",
        "%cd Data/Dataset\n",
        "for rarfile in os.listdir('.'):\n",
        "  !unrar x $rarfile\n",
        "!rm *.rar\n",
        "%cd ../..\n",
        "\n",
        "!pip install av\n",
        "%cd AVID-CMA\n",
        "\n",
        "# change view to reshape in metrics_utils.py line 24\n",
        "# change paths in hmdb.py to '../Data/Dataset' and '../Data/Splits'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irEkglLPRxvr",
        "outputId": "f5376978-9691-4320-ae68-7e4fab3a9d98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/cs753-hacker\n",
            "Cloning into 'AVID-CMA'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 94 (delta 20), reused 15 (delta 15), pack-reused 50\u001b[K\n",
            "Unpacking objects: 100% (94/94), 16.57 MiB | 4.32 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval-action-recg.py configs/benchmark/hmdb51/8at16-fold1.yaml configs/main/avid/kinetics/Cross-N1024.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHXmTwzQX8IU",
        "outputId": "25de9be9-2186-4ca8-b88b-fbfd1f6252c8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================   Config   ==============================\n",
            "required_devices: 8\n",
            "resume: False\n",
            "no_test: False\n",
            "test_only: False\n",
            "debug: False\n",
            "seed: 0\n",
            "distributed: False\n",
            "test_freq: 5\n",
            "num_workers: 2\n",
            "benchmark\n",
            "  name: hmdb51-wucls-8at16\n",
            "dataset\n",
            "  name: hmdb51\n",
            "  fold: 1\n",
            "  batch_size: 32\n",
            "  clip_duration: 0.5\n",
            "  video_fps: 16.0\n",
            "  crop_size: 200\n",
            "  transform: msc+color\n",
            "  min_area: 0.08\n",
            "  color: [1.0, 1.0, 1.0, 0.2]\n",
            "  train\n",
            "    split: train-split{fold}\n",
            "    mode: clip\n",
            "    clips_per_video: 25\n",
            "    use_augmentation: True\n",
            "    use_shuffle: True\n",
            "    drop_last: True\n",
            "  test\n",
            "    split: test-split{fold}\n",
            "    mode: clip\n",
            "    clips_per_video: 1\n",
            "    use_augmentation: False\n",
            "    use_shuffle: False\n",
            "    drop_last: False\n",
            "  test_dense\n",
            "    split: test-split{fold}\n",
            "    mode: video\n",
            "    clips_per_video: 10\n",
            "    use_augmentation: False\n",
            "    use_shuffle: False\n",
            "    drop_last: False\n",
            "optimizer\n",
            "  name: adam\n",
            "  num_epochs: 10\n",
            "  weight_decay: 0.02\n",
            "  warmup_classifier: True\n",
            "  lr\n",
            "    name: multistep\n",
            "    base_lr: 0.001\n",
            "    gamma: 0.5\n",
            "    milestones: [2, 5, 8]\n",
            "model\n",
            "  name: ClassificationWrapper\n",
            "  args\n",
            "    n_classes: 51\n",
            "    feat_name: pool\n",
            "    pooling_op: None\n",
            "    feat_dim: 512\n",
            "    use_dropout: True\n",
            "    dropout: 0.4\n",
            "==============================   Model Config   ==============================\n",
            "name: Cross-N1024\n",
            "model_dir: checkpoints/AVID/Kinetics\n",
            "arch: av_wrapper\n",
            "args\n",
            "  proj_dim: [512, 512, 128]\n",
            "  video_backbone: R2Plus1D\n",
            "  video_backbone_args\n",
            "    depth: 18\n",
            "  audio_backbone: Conv2D\n",
            "  audio_backbone_args\n",
            "    depth: 10\n",
            "==============================   Model   ==============================\n",
            "ClassificationWrapper(\n",
            "  (feature_extractor): R2Plus1D(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
            "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (conv2x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv3x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv4x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv5x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (pool): AdaptiveMaxPool3d(output_size=(1, 1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (classifier): Linear(in_features=512, out_features=51, bias=True)\n",
            ")\n",
            "==============================   Parameters   ==============================\n",
            "feature_extractor.conv1.0.weight                                       | Trainable  | 64 x 3 x 3 x 7 x 7             | 28224\n",
            "feature_extractor.conv1.1.weight                                       | Trainable  | 64                             | 64\n",
            "feature_extractor.conv1.1.bias                                         | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_conv1.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.0.spt_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_conv1.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.0.tmp_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_conv2.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.0.spt_bn2.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_bn2.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_conv2.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.0.out_bn.weight                               | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.out_bn.bias                                 | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_conv1.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.1.spt_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_conv1.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.1.tmp_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_conv2.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.1.spt_bn2.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_bn2.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_conv2.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.1.out_bn.weight                               | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.out_bn.bias                                 | Trainable  | 64                             | 64\n",
            "feature_extractor.conv3x.0.spt_conv1.weight                            | Trainable  | 128 x 64 x 1 x 3 x 3           | 73728\n",
            "feature_extractor.conv3x.0.spt_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_conv1.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.0.tmp_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_conv2.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.0.spt_bn2.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_bn2.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_conv2.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.0.out_bn.weight                               | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.out_bn.bias                                 | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.res_conv.weight                             | Trainable  | 128 x 64 x 1 x 1 x 1           | 8192\n",
            "feature_extractor.conv3x.1.spt_conv1.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.1.spt_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_conv1.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.1.tmp_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_conv2.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.1.spt_bn2.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_bn2.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_conv2.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.1.out_bn.weight                               | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.out_bn.bias                                 | Trainable  | 128                            | 128\n",
            "feature_extractor.conv4x.0.spt_conv1.weight                            | Trainable  | 256 x 128 x 1 x 3 x 3          | 294912\n",
            "feature_extractor.conv4x.0.spt_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_conv1.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.0.tmp_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_conv2.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.0.spt_bn2.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_bn2.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_conv2.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.0.out_bn.weight                               | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.out_bn.bias                                 | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.res_conv.weight                             | Trainable  | 256 x 128 x 1 x 1 x 1          | 32768\n",
            "feature_extractor.conv4x.1.spt_conv1.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.1.spt_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_conv1.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.1.tmp_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_conv2.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.1.spt_bn2.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_bn2.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_conv2.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.1.out_bn.weight                               | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.out_bn.bias                                 | Trainable  | 256                            | 256\n",
            "feature_extractor.conv5x.0.spt_conv1.weight                            | Trainable  | 512 x 256 x 1 x 3 x 3          | 1179648\n",
            "feature_extractor.conv5x.0.spt_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_conv1.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.0.tmp_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_conv2.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.0.spt_bn2.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_bn2.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_conv2.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.0.out_bn.weight                               | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.out_bn.bias                                 | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.res_conv.weight                             | Trainable  | 512 x 256 x 1 x 1 x 1          | 131072\n",
            "feature_extractor.conv5x.1.spt_conv1.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.1.spt_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_conv1.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.1.tmp_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_conv2.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.1.spt_bn2.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_bn2.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_conv2.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.1.out_bn.weight                               | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.out_bn.bias                                 | Trainable  | 512                            | 512\n",
            "classifier.weight                                                      | Trainable  | 51 x 512                       | 26112\n",
            "classifier.bias                                                        | Trainable  | 51                             | 51\n",
            "\n",
            "==============================   Pretrained model   ==============================\n",
            "File: checkpoints/AVID/Kinetics/Cross-N1024/checkpoint.pth.tar\n",
            "Epoch: 22\n",
            "==============================   Train DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: train-split1\n",
            " - Num videos: 3570\n",
            " - Num samples: 89250\n",
            " - Example video: ../Data/Dataset/brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_0.avi\n",
            "\n",
            "==============================   Test DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: test-split1\n",
            " - Num videos: 1530\n",
            " - Num samples: 1530\n",
            " - Example video: ../Data/Dataset/brush_hair/Aussie_Brunette_Brushing_Long_Hair_brush_hair_u_nm_np1_ba_med_3.avi\n",
            "\n",
            "==============================   Dense DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: test-split1\n",
            " - Num videos: 1530\n",
            " - Num samples: 15300\n",
            " - Example video: ../Data/Dataset/brush_hair/Aussie_Brunette_Brushing_Long_Hair_brush_hair_u_nm_np1_ba_med_3.avi\n",
            "\n",
            "==============================   Training   ==============================\n",
            "\n",
            "train: Epoch 0\n",
            "2023-04-26 16:30:01.356085 | train [0][   1/2789]\tTime  5.926 ( 5.926)\tData  4.417 ( 4.417)\tLoss 6.7130e+00 (6.7130e+00)\tAcc@1   3.12 (  3.12)\tAcc@5   9.38 (  9.38)\n",
            "2023-04-26 16:33:15.575252 | train [0][ 100/2789]\tTime  0.955 ( 2.001)\tData  0.005 ( 1.411)\tLoss 5.3687e+00 (5.8666e+00)\tAcc@1   9.38 (  4.84)\tAcc@5  21.88 ( 19.06)\n",
            "2023-04-26 16:36:34.818738 | train [0][ 200/2789]\tTime  0.950 ( 1.992)\tData  0.000 ( 1.359)\tLoss 4.1509e+00 (5.4425e+00)\tAcc@1  15.62 (  7.78)\tAcc@5  43.75 ( 25.83)\n",
            "2023-04-26 16:39:56.711272 | train [0][ 300/2789]\tTime  0.942 ( 2.019)\tData  0.085 ( 1.389)\tLoss 4.2261e+00 (5.1473e+00)\tAcc@1  12.50 (  9.97)\tAcc@5  31.25 ( 30.67)\n",
            "Traceback (most recent call last):\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}