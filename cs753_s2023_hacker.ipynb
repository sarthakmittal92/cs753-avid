{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deY1RziORObc",
        "outputId": "93a90eb0-d8ee-4cd5-d864-9c3142cc1f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# https://drive.google.com/drive/folders/1Tj1rGwyztX2MRlV1DkeBAPTbtoC9_-84?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# clone the repo\n",
        "%cd /content/drive/MyDrive\n",
        "%mkdir -p cs753-hacker\n",
        "%cd cs753-hacker\n",
        "!git clone https://github.com/facebookresearch/AVID-CMA\n",
        "\n",
        "# get the checkpoint\n",
        "%cd AVID-CMA\n",
        "%mkdir -p checkpoints/AVID/Kinetics/Cross-N1024\n",
        "!wget https://dl.fbaipublicfiles.com/avid-cma/checkpoints/AVID_Kinetics_Cross-N1024_checkpoint.pth.tar\n",
        "!mv AVID_Kinetics_Cross-N1024_checkpoint.pth.tar checkpoint.pth.tar\n",
        "!mv checkpoint.pth.tar checkpoints/AVID/Kinetics/Cross-N1024\n",
        "%cd ..\n",
        "\n",
        "# get the dataset\n",
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "!sudo apt install unrar\n",
        "!unrar x hmdb51_org.rar\n",
        "%mkdir -p Dataset\n",
        "!rm -rf hmdb51_org.rar\n",
        "%mv *.rar Dataset\n",
        "\n",
        "# get the splits\n",
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
        "!unrar x test_train_splits.rar\n",
        "%mkdir -p Data\n",
        "!mv Dataset Data\n",
        "!mv testTrainMulti_7030_splits Splits\n",
        "!mv Splits Data\n",
        "\n",
        "import os\n",
        "%cd Data/Dataset\n",
        "for rarfile in os.listdir('.'):\n",
        "  !unrar x $rarfile\n",
        "!rm *.rar\n",
        "%cd ../..\n",
        "\n",
        "!pip install av\n",
        "%cd AVID-CMA\n",
        "\n",
        "# change view to reshape in metrics_utils.py line 24\n",
        "# change paths in hmdb.py to '../Data/Dataset' and '../Data/Splits'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irEkglLPRxvr",
        "outputId": "f5376978-9691-4320-ae68-7e4fab3a9d98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/cs753-hacker\n",
            "Cloning into 'AVID-CMA'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 94 (delta 20), reused 15 (delta 15), pack-reused 50\u001b[K\n",
            "Unpacking objects: 100% (94/94), 16.57 MiB | 4.32 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval-action-recg.py configs/benchmark/hmdb51/8at16-fold1.yaml configs/main/avid/kinetics/Cross-N1024.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHXmTwzQX8IU",
        "outputId": "b6a4df07-873f-4e9c-efd1-3153b521caa2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================   Config   ==============================\n",
            "required_devices: 8\n",
            "resume: False\n",
            "no_test: False\n",
            "test_only: False\n",
            "debug: False\n",
            "seed: 0\n",
            "distributed: False\n",
            "test_freq: 5\n",
            "num_workers: 2\n",
            "benchmark\n",
            "  name: hmdb51-wucls-8at16\n",
            "dataset\n",
            "  name: hmdb51\n",
            "  fold: 1\n",
            "  batch_size: 32\n",
            "  clip_duration: 0.5\n",
            "  video_fps: 16.0\n",
            "  crop_size: 200\n",
            "  transform: msc+color\n",
            "  min_area: 0.08\n",
            "  color: [1.0, 1.0, 1.0, 0.2]\n",
            "  train\n",
            "    split: train-split{fold}\n",
            "    mode: clip\n",
            "    clips_per_video: 25\n",
            "    use_augmentation: True\n",
            "    use_shuffle: True\n",
            "    drop_last: True\n",
            "  test\n",
            "    split: test-split{fold}\n",
            "    mode: clip\n",
            "    clips_per_video: 1\n",
            "    use_augmentation: False\n",
            "    use_shuffle: False\n",
            "    drop_last: False\n",
            "  test_dense\n",
            "    split: test-split{fold}\n",
            "    mode: video\n",
            "    clips_per_video: 10\n",
            "    use_augmentation: False\n",
            "    use_shuffle: False\n",
            "    drop_last: False\n",
            "optimizer\n",
            "  name: adam\n",
            "  num_epochs: 10\n",
            "  weight_decay: 0.02\n",
            "  warmup_classifier: True\n",
            "  lr\n",
            "    name: multistep\n",
            "    base_lr: 0.001\n",
            "    gamma: 0.5\n",
            "    milestones: [2, 5, 8]\n",
            "model\n",
            "  name: ClassificationWrapper\n",
            "  args\n",
            "    n_classes: 51\n",
            "    feat_name: pool\n",
            "    pooling_op: None\n",
            "    feat_dim: 512\n",
            "    use_dropout: True\n",
            "    dropout: 0.4\n",
            "==============================   Model Config   ==============================\n",
            "name: Cross-N1024\n",
            "model_dir: checkpoints/AVID/Kinetics\n",
            "arch: av_wrapper\n",
            "args\n",
            "  proj_dim: [512, 512, 128]\n",
            "  video_backbone: R2Plus1D\n",
            "  video_backbone_args\n",
            "    depth: 18\n",
            "  audio_backbone: Conv2D\n",
            "  audio_backbone_args\n",
            "    depth: 10\n",
            "==============================   Model   ==============================\n",
            "ClassificationWrapper(\n",
            "  (feature_extractor): R2Plus1D(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
            "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (conv2x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv3x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv4x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv5x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (pool): AdaptiveMaxPool3d(output_size=(1, 1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (classifier): Linear(in_features=512, out_features=51, bias=True)\n",
            ")\n",
            "==============================   Parameters   ==============================\n",
            "feature_extractor.conv1.0.weight                                       | Trainable  | 64 x 3 x 3 x 7 x 7             | 28224\n",
            "feature_extractor.conv1.1.weight                                       | Trainable  | 64                             | 64\n",
            "feature_extractor.conv1.1.bias                                         | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_conv1.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.0.spt_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_conv1.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.0.tmp_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_conv2.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.0.spt_bn2.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_bn2.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_conv2.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.0.out_bn.weight                               | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.out_bn.bias                                 | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_conv1.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.1.spt_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_conv1.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.1.tmp_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_conv2.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.1.spt_bn2.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_bn2.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_conv2.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.1.out_bn.weight                               | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.out_bn.bias                                 | Trainable  | 64                             | 64\n",
            "feature_extractor.conv3x.0.spt_conv1.weight                            | Trainable  | 128 x 64 x 1 x 3 x 3           | 73728\n",
            "feature_extractor.conv3x.0.spt_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_conv1.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.0.tmp_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_conv2.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.0.spt_bn2.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_bn2.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_conv2.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.0.out_bn.weight                               | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.out_bn.bias                                 | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.res_conv.weight                             | Trainable  | 128 x 64 x 1 x 1 x 1           | 8192\n",
            "feature_extractor.conv3x.1.spt_conv1.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.1.spt_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_conv1.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.1.tmp_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_conv2.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.1.spt_bn2.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_bn2.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_conv2.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.1.out_bn.weight                               | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.out_bn.bias                                 | Trainable  | 128                            | 128\n",
            "feature_extractor.conv4x.0.spt_conv1.weight                            | Trainable  | 256 x 128 x 1 x 3 x 3          | 294912\n",
            "feature_extractor.conv4x.0.spt_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_conv1.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.0.tmp_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_conv2.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.0.spt_bn2.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_bn2.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_conv2.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.0.out_bn.weight                               | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.out_bn.bias                                 | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.res_conv.weight                             | Trainable  | 256 x 128 x 1 x 1 x 1          | 32768\n",
            "feature_extractor.conv4x.1.spt_conv1.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.1.spt_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_conv1.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.1.tmp_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_conv2.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.1.spt_bn2.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_bn2.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_conv2.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.1.out_bn.weight                               | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.out_bn.bias                                 | Trainable  | 256                            | 256\n",
            "feature_extractor.conv5x.0.spt_conv1.weight                            | Trainable  | 512 x 256 x 1 x 3 x 3          | 1179648\n",
            "feature_extractor.conv5x.0.spt_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_conv1.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.0.tmp_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_conv2.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.0.spt_bn2.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_bn2.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_conv2.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.0.out_bn.weight                               | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.out_bn.bias                                 | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.res_conv.weight                             | Trainable  | 512 x 256 x 1 x 1 x 1          | 131072\n",
            "feature_extractor.conv5x.1.spt_conv1.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.1.spt_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_conv1.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.1.tmp_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_conv2.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.1.spt_bn2.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_bn2.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_conv2.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.1.out_bn.weight                               | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.out_bn.bias                                 | Trainable  | 512                            | 512\n",
            "classifier.weight                                                      | Trainable  | 51 x 512                       | 26112\n",
            "classifier.bias                                                        | Trainable  | 51                             | 51\n",
            "\n",
            "==============================   Pretrained model   ==============================\n",
            "File: checkpoints/AVID/Kinetics/Cross-N1024/checkpoint.pth.tar\n",
            "Epoch: 22\n",
            "==============================   Train DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: train-split1\n",
            " - Num videos: 3570\n",
            " - Num samples: 89250\n",
            " - Example video: ../Data/Dataset/brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_0.avi\n",
            "\n",
            "==============================   Test DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: test-split1\n",
            " - Num videos: 1530\n",
            " - Num samples: 1530\n",
            " - Example video: ../Data/Dataset/brush_hair/Aussie_Brunette_Brushing_Long_Hair_brush_hair_u_nm_np1_ba_med_3.avi\n",
            "\n",
            "==============================   Dense DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: test-split1\n",
            " - Num videos: 1530\n",
            " - Num samples: 15300\n",
            " - Example video: ../Data/Dataset/brush_hair/Aussie_Brunette_Brushing_Long_Hair_brush_hair_u_nm_np1_ba_med_3.avi\n",
            "\n",
            "==============================   Training   ==============================\n",
            "\n",
            "train: Epoch 0\n",
            "2023-04-26 12:13:49.891846 | train [0][   1/2789]\tTime  6.269 ( 6.269)\tData  4.088 ( 4.088)\tLoss 4.8062e+00 (4.8062e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   6.25 (  6.25)\n",
            "2023-04-26 12:17:09.786923 | train [0][ 100/2789]\tTime  1.020 ( 2.062)\tData  0.000 ( 1.416)\tLoss 3.7174e+00 (4.2587e+00)\tAcc@1   3.12 (  4.25)\tAcc@5  25.00 ( 18.50)\n",
            "2023-04-26 12:20:28.450159 | train [0][ 200/2789]\tTime  1.000 ( 1.987)\tData  0.194 ( 1.349)\tLoss 3.5857e+00 (3.9604e+00)\tAcc@1   9.38 (  7.31)\tAcc@5  46.88 ( 25.72)\n",
            "2023-04-26 12:23:48.530314 | train [0][ 300/2789]\tTime  0.987 ( 2.001)\tData  0.000 ( 1.375)\tLoss 3.2230e+00 (3.7560e+00)\tAcc@1  18.75 (  9.99)\tAcc@5  46.88 ( 31.07)\n",
            "2023-04-26 12:27:06.700683 | train [0][ 400/2789]\tTime  0.999 ( 1.982)\tData  0.000 ( 1.331)\tLoss 3.4407e+00 (3.6083e+00)\tAcc@1  15.62 ( 12.09)\tAcc@5  31.25 ( 35.05)\n",
            "2023-04-26 12:30:29.444577 | train [0][ 500/2789]\tTime  0.993 ( 2.027)\tData  0.212 ( 1.393)\tLoss 2.9539e+00 (3.5086e+00)\tAcc@1  21.88 ( 13.66)\tAcc@5  56.25 ( 37.70)\n",
            "2023-04-26 12:33:41.365761 | train [0][ 600/2789]\tTime  1.316 ( 1.919)\tData  1.045 ( 1.589)\tLoss 3.1007e+00 (3.4386e+00)\tAcc@1  21.88 ( 14.70)\tAcc@5  46.88 ( 39.75)\n",
            "2023-04-26 12:36:49.001266 | train [0][ 700/2789]\tTime  1.856 ( 1.876)\tData  1.579 ( 1.595)\tLoss 3.2263e+00 (3.3789e+00)\tAcc@1  12.50 ( 15.76)\tAcc@5  50.00 ( 41.17)\n",
            "2023-04-26 12:39:58.409683 | train [0][ 800/2789]\tTime  0.991 ( 1.894)\tData  0.178 ( 1.535)\tLoss 2.5405e+00 (3.3275e+00)\tAcc@1  40.62 ( 16.82)\tAcc@5  68.75 ( 42.77)\n",
            "2023-04-26 12:43:19.253084 | train [0][ 900/2789]\tTime  0.986 ( 2.008)\tData  0.000 ( 1.356)\tLoss 3.0490e+00 (3.2832e+00)\tAcc@1  15.62 ( 17.61)\tAcc@5  46.88 ( 44.10)\n",
            "2023-04-26 12:46:38.556947 | train [0][1000/2789]\tTime  0.990 ( 1.993)\tData  0.000 ( 1.344)\tLoss 2.5645e+00 (3.2466e+00)\tAcc@1  40.62 ( 18.33)\tAcc@5  62.50 ( 45.19)\n",
            "2023-04-26 12:49:57.532163 | train [0][1100/2789]\tTime  0.982 ( 1.990)\tData  0.000 ( 1.341)\tLoss 2.4563e+00 (3.2160e+00)\tAcc@1  28.12 ( 18.84)\tAcc@5  71.88 ( 46.04)\n",
            "2023-04-26 12:53:17.474044 | train [0][1200/2789]\tTime  0.988 ( 1.999)\tData  0.000 ( 1.350)\tLoss 2.6321e+00 (3.1931e+00)\tAcc@1  18.75 ( 19.35)\tAcc@5  62.50 ( 46.71)\n",
            "2023-04-26 12:56:35.470531 | train [0][1300/2789]\tTime  0.993 ( 1.980)\tData  0.000 ( 1.329)\tLoss 2.6121e+00 (3.1659e+00)\tAcc@1  34.38 ( 19.87)\tAcc@5  50.00 ( 47.49)\n",
            "2023-04-26 12:59:48.891377 | train [0][1400/2789]\tTime  1.437 ( 1.934)\tData  1.139 ( 1.421)\tLoss 2.6765e+00 (3.1464e+00)\tAcc@1  25.00 ( 20.23)\tAcc@5  59.38 ( 48.03)\n",
            "2023-04-26 13:02:59.232270 | train [0][1500/2789]\tTime  0.993 ( 1.903)\tData  0.000 ( 1.509)\tLoss 2.5242e+00 (3.1295e+00)\tAcc@1  28.12 ( 20.49)\tAcc@5  71.88 ( 48.52)\n",
            "2023-04-26 13:06:13.157188 | train [0][1600/2789]\tTime  2.669 ( 1.939)\tData  2.371 ( 1.434)\tLoss 3.2018e+00 (3.1126e+00)\tAcc@1  21.88 ( 20.77)\tAcc@5  53.12 ( 48.97)\n",
            "2023-04-26 13:09:27.615041 | train [0][1700/2789]\tTime  1.819 ( 1.944)\tData  1.545 ( 1.491)\tLoss 3.0763e+00 (3.0947e+00)\tAcc@1  28.12 ( 21.08)\tAcc@5  43.75 ( 49.50)\n",
            "2023-04-26 13:12:46.884925 | train [0][1800/2789]\tTime  2.532 ( 1.993)\tData  2.258 ( 1.390)\tLoss 2.9612e+00 (3.0822e+00)\tAcc@1  21.88 ( 21.27)\tAcc@5  56.25 ( 49.85)\n",
            "2023-04-26 13:16:04.400320 | train [0][1900/2789]\tTime  3.823 ( 1.975)\tData  3.481 ( 1.378)\tLoss 2.5785e+00 (3.0721e+00)\tAcc@1  34.38 ( 21.51)\tAcc@5  71.88 ( 50.15)\n",
            "2023-04-26 13:19:19.456334 | train [0][2000/2789]\tTime  1.422 ( 1.950)\tData  1.147 ( 1.392)\tLoss 2.7434e+00 (3.0603e+00)\tAcc@1  25.00 ( 21.74)\tAcc@5  53.12 ( 50.46)\n",
            "2023-04-26 13:22:27.299170 | train [0][2100/2789]\tTime  1.579 ( 1.878)\tData  1.311 ( 1.598)\tLoss 3.5253e+00 (3.0516e+00)\tAcc@1   9.38 ( 21.90)\tAcc@5  40.62 ( 50.71)\n",
            "2023-04-26 13:25:34.884582 | train [0][2200/2789]\tTime  1.508 ( 1.876)\tData  1.230 ( 1.594)\tLoss 2.9174e+00 (3.0434e+00)\tAcc@1  18.75 ( 22.09)\tAcc@5  56.25 ( 50.98)\n",
            "2023-04-26 13:28:53.316733 | train [0][2300/2789]\tTime  4.147 ( 1.984)\tData  3.800 ( 1.506)\tLoss 3.2901e+00 (3.0339e+00)\tAcc@1  15.62 ( 22.30)\tAcc@5  53.12 ( 51.19)\n",
            "2023-04-26 13:32:03.133882 | train [0][2400/2789]\tTime  1.824 ( 1.898)\tData  1.535 ( 1.607)\tLoss 2.5535e+00 (3.0255e+00)\tAcc@1  37.50 ( 22.45)\tAcc@5  62.50 ( 51.40)\n",
            "2023-04-26 13:35:16.303435 | train [0][2500/2789]\tTime  2.381 ( 1.932)\tData  2.112 ( 1.577)\tLoss 2.7391e+00 (3.0180e+00)\tAcc@1  25.00 ( 22.63)\tAcc@5  56.25 ( 51.63)\n",
            "2023-04-26 13:38:37.658482 | train [0][2600/2789]\tTime  2.230 ( 2.013)\tData  1.955 ( 1.383)\tLoss 3.0939e+00 (3.0128e+00)\tAcc@1  31.25 ( 22.76)\tAcc@5  65.62 ( 51.75)\n",
            "2023-04-26 13:42:00.128845 | train [0][2700/2789]\tTime  2.606 ( 2.025)\tData  2.317 ( 1.380)\tLoss 3.4642e+00 (3.0061e+00)\tAcc@1  18.75 ( 22.87)\tAcc@5  50.00 ( 51.95)\n",
            "2023-04-26 13:45:02.431169 | train [0][2789/2789]\tTime  0.997 ( 2.038)\tData  0.000 ( 1.395)\tLoss 3.1467e+00 (3.0015e+00)\tAcc@1  21.88 ( 22.97)\tAcc@5  43.75 ( 52.06)\n",
            "\n",
            "test: Epoch 0\n",
            "2023-04-26 13:45:06.268379 | test [0][ 1/48]\tTime  3.041 ( 3.041)\tData  2.717 ( 2.717)\tLoss 2.0051e+00 (2.0051e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  75.00 ( 75.00)\n",
            "2023-04-26 13:46:01.619100 | test [0][48/48]\tTime  0.204 ( 1.216)\tData  0.000 ( 0.955)\tLoss 4.6933e+00 (2.5513e+00)\tAcc@1   0.00 ( 31.11)\tAcc@5   7.69 ( 63.40)\n",
            "\n",
            "train: Epoch 1\n",
            "2023-04-26 13:46:05.433401 | train [1][   1/2789]\tTime  3.770 ( 3.770)\tData  3.434 ( 3.434)\tLoss 2.4308e+00 (2.4308e+00)\tAcc@1  25.00 ( 25.00)\tAcc@5  62.50 ( 62.50)\n",
            "2023-04-26 13:49:21.833142 | train [1][ 100/2789]\tTime  2.586 ( 2.002)\tData  2.297 ( 1.563)\tLoss 3.0693e+00 (2.8535e+00)\tAcc@1  18.75 ( 25.66)\tAcc@5  50.00 ( 54.56)\n",
            "2023-04-26 13:52:36.047991 | train [1][ 200/2789]\tTime  2.693 ( 1.942)\tData  2.417 ( 1.510)\tLoss 2.9016e+00 (2.8359e+00)\tAcc@1  37.50 ( 25.84)\tAcc@5  59.38 ( 55.81)\n",
            "2023-04-26 13:55:56.040024 | train [1][ 300/2789]\tTime  2.232 ( 2.000)\tData  1.955 ( 1.427)\tLoss 2.7858e+00 (2.8454e+00)\tAcc@1  25.00 ( 25.90)\tAcc@5  50.00 ( 55.77)\n",
            "2023-04-26 13:59:11.722996 | train [1][ 400/2789]\tTime  4.031 ( 1.957)\tData  3.670 ( 1.519)\tLoss 2.8374e+00 (2.8390e+00)\tAcc@1  25.00 ( 26.05)\tAcc@5  56.25 ( 56.22)\n",
            "2023-04-26 14:02:29.182640 | train [1][ 500/2789]\tTime  2.457 ( 1.975)\tData  2.187 ( 1.384)\tLoss 2.8770e+00 (2.8447e+00)\tAcc@1  28.12 ( 25.95)\tAcc@5  65.62 ( 56.44)\n",
            "2023-04-26 14:05:54.166178 | train [1][ 600/2789]\tTime  2.685 ( 2.050)\tData  2.397 ( 1.407)\tLoss 3.1049e+00 (2.8445e+00)\tAcc@1  25.00 ( 25.91)\tAcc@5  50.00 ( 56.50)\n",
            "2023-04-26 14:09:21.318638 | train [1][ 700/2789]\tTime  2.758 ( 2.071)\tData  2.475 ( 1.432)\tLoss 2.5212e+00 (2.8516e+00)\tAcc@1  34.38 ( 25.83)\tAcc@5  71.88 ( 56.28)\n",
            "2023-04-26 14:12:48.963676 | train [1][ 800/2789]\tTime  2.405 ( 2.076)\tData  2.135 ( 1.431)\tLoss 2.5051e+00 (2.8533e+00)\tAcc@1  28.12 ( 25.70)\tAcc@5  59.38 ( 56.09)\n",
            "\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}