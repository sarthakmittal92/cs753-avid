{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deY1RziORObc",
        "outputId": "a4441f8d-5949-4248-e3e6-878701a4bb93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# https://drive.google.com/drive/folders/1Tj1rGwyztX2MRlV1DkeBAPTbtoC9_-84?usp=share_link"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# clone the repo\n",
        "%cd /content/drive/MyDrive\n",
        "%mkdir -p cs753-hacker\n",
        "%cd cs753-hacker\n",
        "!git clone https://github.com/facebookresearch/AVID-CMA\n",
        "\n",
        "# get the checkpoint\n",
        "%cd AVID-CMA\n",
        "%mkdir -p checkpoints/AVID/Kinetics/Cross-N1024\n",
        "!wget https://dl.fbaipublicfiles.com/avid-cma/checkpoints/AVID_Kinetics_Cross-N1024_checkpoint.pth.tar\n",
        "!mv AVID_Kinetics_Cross-N1024_checkpoint.pth.tar checkpoint.pth.tar\n",
        "!mv checkpoint.pth.tar checkpoints/AVID/Kinetics/Cross-N1024\n",
        "%cd ..\n",
        "\n",
        "# get the dataset\n",
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
        "!sudo apt install unrar\n",
        "!unrar x hmdb51_org.rar\n",
        "%mkdir -p Dataset\n",
        "!rm -rf hmdb51_org.rar\n",
        "%mv *.rar Dataset\n",
        "\n",
        "# get the splits\n",
        "!wget http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.rar\n",
        "!unrar x test_train_splits.rar\n",
        "%mkdir -p Data\n",
        "!mv Dataset Data\n",
        "!mv testTrainMulti_7030_splits Splits\n",
        "!mv Splits Data\n",
        "\n",
        "import os\n",
        "%cd Data/Dataset\n",
        "for rarfile in os.listdir('.'):\n",
        "  !unrar x $rarfile\n",
        "!rm *.rar\n",
        "%cd ../..\n",
        "\n",
        "!pip install av\n",
        "%cd AVID-CMA\n",
        "\n",
        "# change view to reshape in metrics_utils.py line 24\n",
        "# change paths in hmdb.py to '../Data/Dataset' and '../Data/Splits'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irEkglLPRxvr",
        "outputId": "f5376978-9691-4320-ae68-7e4fab3a9d98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/cs753-hacker\n",
            "Cloning into 'AVID-CMA'...\n",
            "remote: Enumerating objects: 94, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 94 (delta 20), reused 15 (delta 15), pack-reused 50\u001b[K\n",
            "Unpacking objects: 100% (94/94), 16.57 MiB | 4.32 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval-action-recg.py configs/benchmark/hmdb51/8at16-fold1.yaml configs/main/avid/kinetics/Cross-N1024.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHXmTwzQX8IU",
        "outputId": "46154cd5-547b-4023-c175-3c9b6e7f70ad"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============================   Config   ==============================\n",
            "required_devices: 8\n",
            "resume: False\n",
            "no_test: False\n",
            "test_only: False\n",
            "debug: False\n",
            "seed: 0\n",
            "distributed: False\n",
            "test_freq: 5\n",
            "num_workers: 2\n",
            "benchmark\n",
            "  name: hmdb51-wucls-8at16\n",
            "dataset\n",
            "  name: hmdb51\n",
            "  fold: 1\n",
            "  batch_size: 32\n",
            "  clip_duration: 0.5\n",
            "  video_fps: 16.0\n",
            "  crop_size: 200\n",
            "  transform: msc+color\n",
            "  min_area: 0.08\n",
            "  color: [1.0, 1.0, 1.0, 0.2]\n",
            "  train\n",
            "    split: train-split{fold}\n",
            "    mode: clip\n",
            "    clips_per_video: 25\n",
            "    use_augmentation: True\n",
            "    use_shuffle: True\n",
            "    drop_last: True\n",
            "  test\n",
            "    split: test-split{fold}\n",
            "    mode: clip\n",
            "    clips_per_video: 1\n",
            "    use_augmentation: False\n",
            "    use_shuffle: False\n",
            "    drop_last: False\n",
            "  test_dense\n",
            "    split: test-split{fold}\n",
            "    mode: video\n",
            "    clips_per_video: 10\n",
            "    use_augmentation: False\n",
            "    use_shuffle: False\n",
            "    drop_last: False\n",
            "optimizer\n",
            "  name: adam\n",
            "  num_epochs: 10\n",
            "  weight_decay: 0.02\n",
            "  warmup_classifier: True\n",
            "  lr\n",
            "    name: multistep\n",
            "    base_lr: 0.001\n",
            "    gamma: 0.5\n",
            "    milestones: [2, 5, 8]\n",
            "model\n",
            "  name: ClassificationWrapper\n",
            "  args\n",
            "    n_classes: 51\n",
            "    feat_name: pool\n",
            "    pooling_op: None\n",
            "    feat_dim: 512\n",
            "    use_dropout: True\n",
            "    dropout: 0.4\n",
            "==============================   Model Config   ==============================\n",
            "name: Cross-N1024\n",
            "model_dir: checkpoints/AVID/Kinetics\n",
            "arch: av_wrapper\n",
            "args\n",
            "  proj_dim: [512, 512, 128]\n",
            "  video_backbone: R2Plus1D\n",
            "  video_backbone_args\n",
            "    depth: 18\n",
            "  audio_backbone: Conv2D\n",
            "  audio_backbone_args\n",
            "    depth: 10\n",
            "==============================   Model   ==============================\n",
            "ClassificationWrapper(\n",
            "  (feature_extractor): R2Plus1D(\n",
            "    (conv1): Sequential(\n",
            "      (0): Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n",
            "      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (conv2x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(64, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv3x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(128, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv4x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(128, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(256, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (conv5x): Sequential(\n",
            "      (0): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(256, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (res_conv): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
            "      )\n",
            "      (1): BasicR2P1DBlock(\n",
            "        (spt_conv1): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv1): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (tmp_bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (spt_conv2): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
            "        (spt_bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (tmp_conv2): Conv3d(512, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
            "        (out_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (pool): AdaptiveMaxPool3d(output_size=(1, 1, 1))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (classifier): Linear(in_features=512, out_features=51, bias=True)\n",
            ")\n",
            "==============================   Parameters   ==============================\n",
            "feature_extractor.conv1.0.weight                                       | Trainable  | 64 x 3 x 3 x 7 x 7             | 28224\n",
            "feature_extractor.conv1.1.weight                                       | Trainable  | 64                             | 64\n",
            "feature_extractor.conv1.1.bias                                         | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_conv1.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.0.spt_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_conv1.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.0.tmp_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_conv2.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.0.spt_bn2.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.spt_bn2.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.tmp_conv2.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.0.out_bn.weight                               | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.0.out_bn.bias                                 | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_conv1.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.1.spt_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_conv1.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.1.tmp_bn1.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_bn1.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_conv2.weight                            | Trainable  | 64 x 64 x 1 x 3 x 3            | 36864\n",
            "feature_extractor.conv2x.1.spt_bn2.weight                              | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.spt_bn2.bias                                | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.tmp_conv2.weight                            | Trainable  | 64 x 64 x 3 x 1 x 1            | 12288\n",
            "feature_extractor.conv2x.1.out_bn.weight                               | Trainable  | 64                             | 64\n",
            "feature_extractor.conv2x.1.out_bn.bias                                 | Trainable  | 64                             | 64\n",
            "feature_extractor.conv3x.0.spt_conv1.weight                            | Trainable  | 128 x 64 x 1 x 3 x 3           | 73728\n",
            "feature_extractor.conv3x.0.spt_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_conv1.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.0.tmp_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_conv2.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.0.spt_bn2.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.spt_bn2.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.tmp_conv2.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.0.out_bn.weight                               | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.out_bn.bias                                 | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.0.res_conv.weight                             | Trainable  | 128 x 64 x 1 x 1 x 1           | 8192\n",
            "feature_extractor.conv3x.1.spt_conv1.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.1.spt_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_conv1.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.1.tmp_bn1.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_bn1.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_conv2.weight                            | Trainable  | 128 x 128 x 1 x 3 x 3          | 147456\n",
            "feature_extractor.conv3x.1.spt_bn2.weight                              | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.spt_bn2.bias                                | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.tmp_conv2.weight                            | Trainable  | 128 x 128 x 3 x 1 x 1          | 49152\n",
            "feature_extractor.conv3x.1.out_bn.weight                               | Trainable  | 128                            | 128\n",
            "feature_extractor.conv3x.1.out_bn.bias                                 | Trainable  | 128                            | 128\n",
            "feature_extractor.conv4x.0.spt_conv1.weight                            | Trainable  | 256 x 128 x 1 x 3 x 3          | 294912\n",
            "feature_extractor.conv4x.0.spt_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_conv1.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.0.tmp_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_conv2.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.0.spt_bn2.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.spt_bn2.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.tmp_conv2.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.0.out_bn.weight                               | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.out_bn.bias                                 | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.0.res_conv.weight                             | Trainable  | 256 x 128 x 1 x 1 x 1          | 32768\n",
            "feature_extractor.conv4x.1.spt_conv1.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.1.spt_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_conv1.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.1.tmp_bn1.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_bn1.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_conv2.weight                            | Trainable  | 256 x 256 x 1 x 3 x 3          | 589824\n",
            "feature_extractor.conv4x.1.spt_bn2.weight                              | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.spt_bn2.bias                                | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.tmp_conv2.weight                            | Trainable  | 256 x 256 x 3 x 1 x 1          | 196608\n",
            "feature_extractor.conv4x.1.out_bn.weight                               | Trainable  | 256                            | 256\n",
            "feature_extractor.conv4x.1.out_bn.bias                                 | Trainable  | 256                            | 256\n",
            "feature_extractor.conv5x.0.spt_conv1.weight                            | Trainable  | 512 x 256 x 1 x 3 x 3          | 1179648\n",
            "feature_extractor.conv5x.0.spt_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_conv1.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.0.tmp_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_conv2.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.0.spt_bn2.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.spt_bn2.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.tmp_conv2.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.0.out_bn.weight                               | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.out_bn.bias                                 | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.0.res_conv.weight                             | Trainable  | 512 x 256 x 1 x 1 x 1          | 131072\n",
            "feature_extractor.conv5x.1.spt_conv1.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.1.spt_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_conv1.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.1.tmp_bn1.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_bn1.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_conv2.weight                            | Trainable  | 512 x 512 x 1 x 3 x 3          | 2359296\n",
            "feature_extractor.conv5x.1.spt_bn2.weight                              | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.spt_bn2.bias                                | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.tmp_conv2.weight                            | Trainable  | 512 x 512 x 3 x 1 x 1          | 786432\n",
            "feature_extractor.conv5x.1.out_bn.weight                               | Trainable  | 512                            | 512\n",
            "feature_extractor.conv5x.1.out_bn.bias                                 | Trainable  | 512                            | 512\n",
            "classifier.weight                                                      | Trainable  | 51 x 512                       | 26112\n",
            "classifier.bias                                                        | Trainable  | 51                             | 51\n",
            "\n",
            "==============================   Pretrained model   ==============================\n",
            "File: checkpoints/AVID/Kinetics/Cross-N1024/checkpoint.pth.tar\n",
            "Epoch: 22\n",
            "==============================   Train DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: train-split1\n",
            " - Num videos: 3570\n",
            " - Num samples: 89250\n",
            " - Example video: ../Data/Dataset/brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_0.avi\n",
            "\n",
            "==============================   Test DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: test-split1\n",
            " - Num videos: 1530\n",
            " - Num samples: 1530\n",
            " - Example video: ../Data/Dataset/brush_hair/Aussie_Brunette_Brushing_Long_Hair_brush_hair_u_nm_np1_ba_med_3.avi\n",
            "\n",
            "==============================   Dense DB   ==============================\n",
            "HMDB-101\n",
            " - Root: ../Data/Dataset\n",
            " - Subset: test-split1\n",
            " - Num videos: 1530\n",
            " - Num samples: 15300\n",
            " - Example video: ../Data/Dataset/brush_hair/Aussie_Brunette_Brushing_Long_Hair_brush_hair_u_nm_np1_ba_med_3.avi\n",
            "\n",
            "==============================   Training   ==============================\n",
            "\n",
            "train: Epoch 0\n",
            "2023-04-26 15:12:54.724067 | train [0][   1/2789]\tTime  5.701 ( 5.701)\tData  3.957 ( 3.957)\tLoss 4.5659e+01 (4.5659e+01)\tAcc@1   3.12 (  3.12)\tAcc@5   6.25 (  6.25)\n",
            "2023-04-26 15:16:15.055271 | train [0][ 100/2789]\tTime  1.006 ( 2.060)\tData  0.000 ( 1.437)\tLoss 1.9274e+01 (2.0696e+01)\tAcc@1   9.38 (  3.06)\tAcc@5  18.75 ( 13.38)\n",
            "2023-04-26 15:19:41.696681 | train [0][ 200/2789]\tTime  0.991 ( 2.066)\tData  0.000 ( 1.414)\tLoss 1.5016e+01 (1.8209e+01)\tAcc@1   3.12 (  5.66)\tAcc@5  37.50 ( 20.58)\n",
            "2023-04-26 15:23:08.633461 | train [0][ 300/2789]\tTime  0.968 ( 2.069)\tData  0.000 ( 1.416)\tLoss 1.9983e+01 (1.7273e+01)\tAcc@1   9.38 (  8.28)\tAcc@5  37.50 ( 26.23)\n",
            "2023-04-26 15:26:34.977053 | train [0][ 400/2789]\tTime  0.966 ( 2.063)\tData  0.000 ( 1.424)\tLoss 1.3535e+01 (1.6711e+01)\tAcc@1  15.62 ( 10.08)\tAcc@5  37.50 ( 30.38)\n",
            "2023-04-26 15:29:59.231897 | train [0][ 500/2789]\tTime  0.958 ( 2.042)\tData  0.000 ( 1.410)\tLoss 1.3721e+01 (1.6252e+01)\tAcc@1  25.00 ( 11.92)\tAcc@5  59.38 ( 33.81)\n",
            "2023-04-26 15:33:22.188871 | train [0][ 600/2789]\tTime  0.973 ( 2.029)\tData  0.000 ( 1.396)\tLoss 1.1226e+01 (1.5972e+01)\tAcc@1  43.75 ( 13.29)\tAcc@5  81.25 ( 36.29)\n",
            "2023-04-26 15:36:47.741286 | train [0][ 700/2789]\tTime  0.968 ( 2.055)\tData  0.000 ( 1.423)\tLoss 1.4651e+01 (1.5724e+01)\tAcc@1  12.50 ( 14.53)\tAcc@5  53.12 ( 38.23)\n",
            "2023-04-26 15:40:10.377931 | train [0][ 800/2789]\tTime  0.968 ( 2.026)\tData  0.000 ( 1.392)\tLoss 1.4502e+01 (1.5522e+01)\tAcc@1  21.88 ( 15.56)\tAcc@5  56.25 ( 39.84)\n",
            "2023-04-26 15:43:36.354024 | train [0][ 900/2789]\tTime  0.985 ( 2.060)\tData  0.000 ( 1.428)\tLoss 1.3179e+01 (1.5361e+01)\tAcc@1  31.25 ( 16.30)\tAcc@5  46.88 ( 41.15)\n",
            "2023-04-26 15:46:59.598215 | train [0][1000/2789]\tTime  0.970 ( 2.032)\tData  0.000 ( 1.398)\tLoss 1.0263e+01 (1.5228e+01)\tAcc@1  28.12 ( 17.09)\tAcc@5  53.12 ( 42.40)\n",
            "2023-04-26 15:50:22.812676 | train [0][1100/2789]\tTime  0.962 ( 2.032)\tData  0.040 ( 1.405)\tLoss 9.6497e+00 (1.5106e+01)\tAcc@1  18.75 ( 17.59)\tAcc@5  50.00 ( 43.41)\n",
            "2023-04-26 15:53:45.919668 | train [0][1200/2789]\tTime  0.962 ( 2.031)\tData  0.000 ( 1.441)\tLoss 1.3521e+01 (1.4999e+01)\tAcc@1  25.00 ( 18.15)\tAcc@5  62.50 ( 44.30)\n",
            "2023-04-26 15:57:01.532854 | train [0][1300/2789]\tTime  0.988 ( 1.956)\tData  0.000 ( 1.489)\tLoss 1.8172e+01 (1.4908e+01)\tAcc@1  18.75 ( 18.56)\tAcc@5  31.25 ( 44.92)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/cs753-hacker/AVID-CMA/eval-action-recg.py\", line 189, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/cs753-hacker/AVID-CMA/eval-action-recg.py\", line 44, in main\n",
            "    main_worker(None, ngpus, cfg['dataset']['fold'], args, cfg)\n",
            "  File \"/content/drive/MyDrive/cs753-hacker/AVID-CMA/eval-action-recg.py\", line 83, in main_worker\n",
            "    run_phase('train', train_loader, model, cls_opt, epoch, args, cfg, logger)\n",
            "  File \"/content/drive/MyDrive/cs753-hacker/AVID-CMA/eval-action-recg.py\", line 137, in run_phase\n",
            "    target = sample['label'].cuda()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}